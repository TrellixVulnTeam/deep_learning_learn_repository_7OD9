{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import d2lzh as d2l\n",
    "import mxnet as mx\n",
    "from mxnet import autograd, gluon , init, nd\n",
    "from mxnet.gluon import loss as gloss, nn\n",
    "import time\n",
    "\n",
    "net = nn.Sequential()\n",
    "net.add(nn.Conv2D(channels=6, kernel_size=5, activation='sigmoid'),\n",
    "        nn.MaxPool2D(pool_size=2, strides=2),\n",
    "        nn.Conv2D(channels=16, kernel_size=5, activation='sigmoid'),\n",
    "        nn.MaxPool2D(pool_size=2, strides=2),\n",
    "        nn.Dense(120, activation='sigmoid'),\n",
    "        nn.Dense(84, activation='sigmoid'),\n",
    "        nn.Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv0 output shape:\t (1, 6, 24, 24)\n",
      "pool0 output shape:\t (1, 6, 12, 12)\n",
      "conv1 output shape:\t (1, 16, 8, 8)\n",
      "pool1 output shape:\t (1, 16, 4, 4)\n",
      "dense0 output shape:\t (1, 120)\n",
      "dense1 output shape:\t (1, 84)\n",
      "dense2 output shape:\t (1, 10)\n"
     ]
    }
   ],
   "source": [
    "X = nd.random.uniform(shape=(1,1,28,28))\n",
    "net.initialize()\n",
    "for layer in net:\n",
    "        X = layer(X)\n",
    "        print(layer.name, 'output shape:\\t', X.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "cpu(0)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def try_gpu():\n",
    "    try:\n",
    "        ctx = mx.gpu()\n",
    "        _ = nd.zeros((1,), ctx=ctx)\n",
    "    except mx.base.MXNetError:\n",
    "        ctx = mx.cpu()\n",
    "    return ctx\n",
    "\n",
    "ctx = try_gpu()\n",
    "ctx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter,net,ctx):\n",
    "    acc_sum, n = nd.array([0], ctx=ctx), 0\n",
    "    for X, y in data_iter:\n",
    "        X, y = X.as_in_context(ctx), y.as_in_context(ctx).astype('float32')\n",
    "        acc_sum += (net(X).argmax(axis=1) == y).sum()\n",
    "        n+=y.size\n",
    "    return acc_sum.asscalar() / n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def train_ch5(net,train_iter,test_iter,batch_size,trainer,ctx,num_epochs):\n",
    "    print('training on', ctx)\n",
    "    loss = gloss.SoftmaxCrossEntropyLoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            X, y = X.as_in_context(ctx), y.as_in_context(ctx)\n",
    "            with autograd.record():\n",
    "                y_hat = net(X)\n",
    "                l = loss(y_hat, y).sum()\n",
    "            l.backward()\n",
    "            trainer.step(batch_size)\n",
    "            y = y.astype('float32')\n",
    "            train_l_sum += l.asscalar()\n",
    "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().asscalar()\n",
    "            n += y.size\n",
    "        test_acc = evaluate_accuracy(test_iter, net, ctx)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.2f sec'\n",
    "              %(epoch+1, train_l_sum/n, train_acc_sum/n, test_acc, time.time()-start))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\dl\\lib\\site-packages\\mxnet\\gluon\\parameter.py:893: UserWarning: Parameter 'conv0_weight' is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
      "  v.initialize(None, ctx, init, force_reinit=force_reinit)\n",
      "E:\\anaconda\\envs\\dl\\lib\\site-packages\\mxnet\\gluon\\parameter.py:893: UserWarning: Parameter 'conv0_bias' is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
      "  v.initialize(None, ctx, init, force_reinit=force_reinit)\n",
      "E:\\anaconda\\envs\\dl\\lib\\site-packages\\mxnet\\gluon\\parameter.py:893: UserWarning: Parameter 'conv1_weight' is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
      "  v.initialize(None, ctx, init, force_reinit=force_reinit)\n",
      "E:\\anaconda\\envs\\dl\\lib\\site-packages\\mxnet\\gluon\\parameter.py:893: UserWarning: Parameter 'conv1_bias' is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
      "  v.initialize(None, ctx, init, force_reinit=force_reinit)\n",
      "E:\\anaconda\\envs\\dl\\lib\\site-packages\\mxnet\\gluon\\parameter.py:893: UserWarning: Parameter 'dense0_weight' is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
      "  v.initialize(None, ctx, init, force_reinit=force_reinit)\n",
      "E:\\anaconda\\envs\\dl\\lib\\site-packages\\mxnet\\gluon\\parameter.py:893: UserWarning: Parameter 'dense0_bias' is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
      "  v.initialize(None, ctx, init, force_reinit=force_reinit)\n",
      "E:\\anaconda\\envs\\dl\\lib\\site-packages\\mxnet\\gluon\\parameter.py:893: UserWarning: Parameter 'dense1_weight' is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
      "  v.initialize(None, ctx, init, force_reinit=force_reinit)\n",
      "E:\\anaconda\\envs\\dl\\lib\\site-packages\\mxnet\\gluon\\parameter.py:893: UserWarning: Parameter 'dense1_bias' is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
      "  v.initialize(None, ctx, init, force_reinit=force_reinit)\n",
      "E:\\anaconda\\envs\\dl\\lib\\site-packages\\mxnet\\gluon\\parameter.py:893: UserWarning: Parameter 'dense2_weight' is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
      "  v.initialize(None, ctx, init, force_reinit=force_reinit)\n",
      "E:\\anaconda\\envs\\dl\\lib\\site-packages\\mxnet\\gluon\\parameter.py:893: UserWarning: Parameter 'dense2_bias' is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
      "  v.initialize(None, ctx, init, force_reinit=force_reinit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cpu(0)\n",
      "epoch 1, loss 2.3152, train acc 0.102, test acc 0.100, time 13.82 sec\n",
      "epoch 2, loss 2.3050, train acc 0.100, test acc 0.100, time 13.84 sec\n",
      "epoch 3, loss 2.3043, train acc 0.100, test acc 0.100, time 19.54 sec\n",
      "epoch 4, loss 2.3039, train acc 0.099, test acc 0.100, time 18.98 sec\n",
      "epoch 5, loss 2.3039, train acc 0.097, test acc 0.100, time 19.04 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epoch =0.9, 5\n",
    "net.initialize(ctx=ctx, init=init.Xavier())\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr})\n",
    "train_ch5(net, train_iter, test_iter, batch_size, trainer, ctx, num_epoch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}